{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3441: DtypeWarning: Columns (0,1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df_rand = pd.read_csv(\n",
    "    '1mio-raw.csv', \n",
    "    delimiter = ',', \n",
    "    header = 0,\n",
    "    skiprows = lambda i: i > 0 and random.random() > 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits a string into list\n",
    "def string_splitter(string):\n",
    "    #if type(string) != str: \n",
    "    lst = str(string).split(\", \")\n",
    "    filter_obj = filter(lambda x: x != \"\", lst)\n",
    "    return list(filter_obj)\n",
    "\n",
    "# Strip a string representation of list of strings\n",
    "def string_stripper(string):\n",
    "    lst = [i.strip() for i in string[1:-1].replace('\\'',\"\").split(',')]\n",
    "    filter_obj = filter(lambda x: x != \"\", lst)\n",
    "    return list(filter_obj)\n",
    "\n",
    "def string_filter(lst):\n",
    "    filters = [lambda x: not x.isdigit(), lambda x: x != \"\"]\n",
    "    filter_obj = filter(lambda x: all([f(x) for f in filters]), lst)\n",
    "    return list(filter_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fnc = df_rand\n",
    "\n",
    "# Dropping columns (setting new ID column later)\n",
    "df_fnc = df_fnc.drop(columns = ['Unnamed: 0', 'id', 'source'])\n",
    "\n",
    "# Set new ID column\n",
    "df_fnc = df_fnc.rename_axis('id').reset_index()\n",
    "df_fnc.set_index('id')\n",
    "\n",
    "df_fnc = df_fnc.astype({'domain':str, 'type':str, 'url':str, 'content':str, 'scraped_at':str, 'inserted_at':str,\n",
    "        'updated_at':str, 'title':str, 'authors':str, 'keywords':str, 'meta_keywords':str,\n",
    "        'meta_description':str, 'tags':str, 'summary':str}, copy = False)\n",
    "\n",
    "# Convert blank fields into NaN\n",
    "# df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "# Replace 'nan' strings with NaN\n",
    "df_fnc = df_fnc.replace(\"nan\", np.nan)\n",
    "\n",
    "# Convert all strings into lower case:\n",
    "# df_fnc = df_fnc.applymap(lambda s: s.lower() if type(s) == str else s)\n",
    "\n",
    "# Fix types\n",
    "type_set = ['fake', 'satire', 'bias', 'conspiracy', 'state', 'junksci', 'hate', 'clickbait', 'unreliable', 'political', 'reliable','rumor']\n",
    "df_fnc['type'] = df_fnc['type'].apply(lambda x: np.nan if x not in type_set else x)\n",
    "\n",
    "# Fix timestamps\n",
    "for column in ['scraped_at','inserted_at','updated_at']:\n",
    "    df_fnc[column] = df_fnc[column].apply(lambda x: pd.to_datetime(x, errors='coerce'))\n",
    "    df_fnc[column] = df_fnc[column].replace({np.NaN: None})\n",
    "\n",
    "# Fix auhtors - separate into list of strings\n",
    "df_fnc['authors'] = df_fnc['authors'].apply(lambda x: string_splitter(x) if pd.notnull(x) else x)\n",
    "\n",
    "# Fix metakeywords - strip a string representation of list of strings\n",
    "df_fnc['meta_keywords'] = df_fnc['meta_keywords'].apply(lambda x: string_stripper(x) if pd.notnull(x) else x)\n",
    "\n",
    "# Fix tags\n",
    "df_fnc['tags'] = df_fnc['tags'].apply(lambda x: string_splitter(x) if pd.notnull(x) else x)\n",
    "df_fnc['tags'] = df_fnc['tags'].apply(lambda x: string_filter(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Replace NaN into empty lists\n",
    "for column in ['authors', 'keywords', 'meta_keywords', 'tags']:\n",
    "    df_fnc[column] = df_fnc[column].fillna(\"\").apply(list)\n",
    "\n",
    "# Remove empty rows\n",
    "df_fnc = df_fnc.dropna(subset = ['title', 'content', 'type'], how = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_fnc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_804/2575196666.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_fnc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_fnc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_fnc' is not defined"
     ]
    }
   ],
   "source": [
    "df_fnc.to_csv('test.csv', index=False)\n",
    "display(df_fnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wn = pd.read_csv('wikinews.csv')\n",
    "\n",
    "# Dropping columns\n",
    "df_wn = df_wn.drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "# Set new ID column\n",
    "df_wn = df_wn.rename_axis('id').reset_index()\n",
    "df_wn.set_index('id')\n",
    "\n",
    "# Fix timestamps\n",
    "for column in ['publish_date', 'modified_date']:\n",
    "    df_wn[column] = df_wn[column].apply(lambda x: pd.to_datetime(x, errors='coerce')).astype('datetime64[D]')\n",
    "    df_wn[column] = df_wn[column].replace({np.NaN: None})\n",
    "\n",
    "# Fix sources\n",
    "df_wn['sources'] = df_wn['sources'].apply(lambda x: string_stripper(x) if pd.notnull(x) else x)\n",
    "\n",
    "# Fix categories\n",
    "df_wn['categories'] = df_wn['categories'].apply(lambda x: string_stripper(x) if pd.notnull(x) else x)\n",
    "\n",
    "# Replace NaN into empty lists\n",
    "for column in ['sources', 'categories']:\n",
    "    df_wn[column] = df_wn[column].fillna(\"\").apply(list)\n",
    "\n",
    "# Remove empty rows\n",
    "df_wn = df_wn.dropna(subset = ['title', 'content'], how = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates the tables of our database\n",
    "\n",
    "fnc_tables = [\"fnc_article\", \"authors\", \"tags\", \"keywords\", \"metakeywords\"]\n",
    "\n",
    "create_fnctables = [\n",
    "    \"\"\"\n",
    "    CREATE TABLE fnc_article (\n",
    "        id INT, \n",
    "        domain VARCHAR, \n",
    "        type VARCHAR, \n",
    "        url VARCHAR, \n",
    "        content VARCHAR, \n",
    "        scraped_at TIMESTAMP, \n",
    "        inserted_at TIMESTAMP,\n",
    "        updated_at TIMESTAMP, \n",
    "        title VARCHAR (256), \n",
    "        meta_description VARCHAR, \n",
    "        summary VARCHAR,\n",
    "\n",
    "        PRIMARY KEY (id) \n",
    "    );\n",
    "    \"\"\"\n",
    "    ,\n",
    "    \"\"\"\n",
    "    CREATE TABLE authors (\n",
    "        a_id INT,\n",
    "        authors VARCHAR,\n",
    "        PRIMARY KEY (a_id, authors),\n",
    "        FOREIGN KEY (a_id)\n",
    "            REFERENCES fnc_article (id)\n",
    "            ON UPDATE CASCADE ON DELETE CASCADE\n",
    "    );\n",
    "    \"\"\"\n",
    "    ,\n",
    "    \"\"\"\n",
    "    CREATE TABLE tags (\n",
    "        a_id INT, \n",
    "        tag VARCHAR, \n",
    "        PRIMARY KEY (a_id, tag),\n",
    "        FOREIGN KEY (a_id)\n",
    "            REFERENCES fnc_article (id)\n",
    "            ON UPDATE CASCADE ON DELETE CASCADE\n",
    "    );\n",
    "    \"\"\"\n",
    "    ,\n",
    "    \"\"\"\n",
    "    CREATE TABLE keywords (\n",
    "        a_id INT, \n",
    "        keyword VARCHAR,\n",
    "        PRIMARY KEY (a_id, keyword),\n",
    "        FOREIGN KEY (a_id)\n",
    "            REFERENCES fnc_article (id)\n",
    "            ON UPDATE CASCADE ON DELETE CASCADE\n",
    "    );\n",
    "    \"\"\"\n",
    "    ,\n",
    "    \"\"\"\n",
    "    CREATE TABLE metakeywords (\n",
    "        a_id INT, \n",
    "        mkeyword VARCHAR,\n",
    "        PRIMARY KEY (a_id, mkeyword),\n",
    "        FOREIGN KEY (a_id)\n",
    "            REFERENCES fnc_article (id)\n",
    "            ON UPDATE CASCADE ON DELETE CASCADE\n",
    "    );\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_tables = [\"wn_article\", \"sources\", \"categories\"]\n",
    "\n",
    "create_wntables = [\n",
    "    \"\"\"\n",
    "    CREATE TABLE wn_article (\n",
    "        id INT, \n",
    "        content VARCHAR, \n",
    "        publish_date TIMESTAMP, \n",
    "        modified_date TIMESTAMP,\n",
    "        title VARCHAR (256), \n",
    "\n",
    "        PRIMARY KEY (id) \n",
    "    );\n",
    "    \"\"\"\n",
    "    ,\n",
    "    \"\"\"\n",
    "    CREATE TABLE sources (\n",
    "        a_id INT,\n",
    "        sources VARCHAR,\n",
    "        PRIMARY KEY (a_id, sources),\n",
    "        FOREIGN KEY (a_id)\n",
    "            REFERENCES wn_article (id)\n",
    "            ON UPDATE CASCADE ON DELETE CASCADE\n",
    "    );\n",
    "    \"\"\"\n",
    "    ,\n",
    "    \"\"\"\n",
    "    CREATE TABLE categories (\n",
    "        a_id INT, \n",
    "        categories VARCHAR, \n",
    "        PRIMARY KEY (a_id, categories),\n",
    "        FOREIGN KEY (a_id)\n",
    "            REFERENCES wn_article (id)\n",
    "            ON UPDATE CASCADE ON DELETE CASCADE\n",
    "    );\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=\"fakenewsdb\", user=\"postgres\", password=\"1234\")\n",
    "\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in (fnc_tables + wn_tables):\n",
    "    cursor.execute(\"DROP TABLE IF EXISTS \" + table + \" CASCADE;\")\n",
    "\n",
    "for sql in (create_fnctables + create_wntables):\n",
    "    cursor.execute(sql)\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of functions that puts the data from pd.dataframe into the right tables. Explodes the dataframe columns with\n",
    "# list of strings into seperate entries each with their own key (a_id, string)\n",
    "\n",
    "def projectrow2tuple(fields, row):\n",
    "    return tuple(map(lambda f: row[f], fields))\n",
    "\n",
    "def insertstring(table, n):\n",
    "    return \"INSERT INTO {} VALUES ({}) ON CONFLICT DO NOTHING\".format(table, \", \".join(map(lambda _: '%s', range(n))))\n",
    "\n",
    "def multi_insert(server, a_id, insert, xs):\n",
    "    for x in xs:\n",
    "        server.execute(insert, (a_id, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_rows_fnc(server, row):\n",
    "    A_domain = ['id', 'domain', 'type', 'url', 'content', 'scraped_at',\n",
    "       'inserted_at', 'updated_at', 'title', 'meta_description', 'summary']\n",
    "    AU_domain = ['id', 'authors']\n",
    "    T_domain = ['id', 'tags']\n",
    "    K_domain = ['id', 'keywords']\n",
    "    MK_domain = ['id', 'meta_keywords']\n",
    "    \n",
    "    Atuple = projectrow2tuple(A_domain, row)\n",
    "    (a_id, tags) = projectrow2tuple(T_domain, row)\n",
    "    (_, au) = projectrow2tuple(AU_domain, row)\n",
    "    (_, kws) = projectrow2tuple(K_domain, row)\n",
    "    (_, mkws) = projectrow2tuple(MK_domain, row)\n",
    "\n",
    "    Ainsert = insertstring(\"fnc_article\", len(Atuple))\n",
    "    Tinsert = insertstring(\"tags\", 2)\n",
    "    AUinsert = insertstring(\"authors\", 2)\n",
    "    Kinsert = insertstring(\"keywords\", 2)\n",
    "    MKinsert = insertstring(\"metakeywords\", 2)\n",
    "\n",
    "    server.execute(Ainsert, Atuple)\n",
    "    insert = lambda ins, xs: multi_insert(server, a_id, ins, xs)\n",
    "    insert(Tinsert, tags)\n",
    "    insert(AUinsert, au)\n",
    "    insert(Kinsert, kws)\n",
    "    insert(MKinsert, mkws)\n",
    "\n",
    "def insert_rows_wn(server, row):\n",
    "    A_domain = ['id', 'content', 'publish_date', 'modified_date', 'title']\n",
    "    S_domain = ['id', 'sources']\n",
    "    C_domain = ['id', 'categories']\n",
    "\n",
    "    Atuple = projectrow2tuple(A_domain, row)\n",
    "    (a_id, src) = projectrow2tuple(S_domain, row)\n",
    "    (a_id, cat) = projectrow2tuple(C_domain, row)\n",
    "\n",
    "    Ainsert = insertstring(\"wn_article\", len(Atuple))\n",
    "    Sinsert = insertstring(\"sources\", 2)\n",
    "    Cinsert = insertstring(\"categories\", 2)\n",
    "\n",
    "    server.execute(Ainsert, Atuple)\n",
    "    insert = lambda ins, xs: multi_insert(server, a_id, ins, xs)\n",
    "    insert(Sinsert, src)\n",
    "    insert(Cinsert, cat)\n",
    "\n",
    "for _, row in df_fnc.iterrows():\n",
    "    insert_rows_fnc(cursor, row)\n",
    "\n",
    "for _, row in df_wn.iterrows():\n",
    "    insert_rows_wn(cursor, row)\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65cc6a082bbdb51aba06bbf1d78c1b93987957587a078c9335da8e443a5b7d28"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
