{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn import linear_model, metrics, naive_bayes, svm, neural_network, ensemble, neighbors\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('new data/X_trainFNC.csv').squeeze()\n",
    "X_test = pd.read_csv('new data/X_testFNC.csv').squeeze()\n",
    "X_valid = pd.read_csv('new data/X_validFNC.csv').squeeze()\n",
    "y_train = pd.read_csv('new data/y_trainFNC.csv').squeeze()\n",
    "y_test = pd.read_csv('new data/y_testFNC.csv').squeeze()\n",
    "y_valid = pd.read_csv('new data/y_validFNC.csv').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = TfidfVectorizer(       \n",
    "    lowercase=False, \n",
    "    ngram_range=(1,1), \n",
    "    token_pattern=r\"(?u)\\b\\w\\w+\\b|<DATE>|<NUM>|<EMAIL>|<URL>\",\n",
    "    min_df=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94077"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(X_train)\n",
    "\n",
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = X_train.shape[0]\n",
    "n_val = X_valid.shape[0]\n",
    "\n",
    "X_trainval = np.concatenate((X_train, X_valid))\n",
    "y_trainval = np.concatenate((y_train, y_valid))\n",
    "\n",
    "test_fold = -1*np.ones(X_trainval.shape[0])\n",
    "test_fold[n_train:] = 0\n",
    "pds = PredefinedSplit(test_fold)\n",
    "\n",
    "TFIDF_Xtrainval = vectorizer.transform(X_trainval)\n",
    "\n",
    "TFIDF_Xtrain = vectorizer.transform(X_train)\n",
    "TFIDF_Xvalid = vectorizer.transform(X_valid)\n",
    "TFIDF_Xtest = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lin Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_model = linear_model.LogisticRegression(max_iter = 200)\n",
    "\n",
    "LR_param = [\n",
    "    {'penalty' : ['l1'], 'C' : np.logspace(-4, 4, 20), 'solver' : ['liblinear'], 'max_iter' : [200]},\n",
    "    {'penalty' : ['l2'], 'C' : np.logspace(-4, 4, 20), 'solver' : ['lbfgs','newton-cg','saga'], 'max_iter' : [200]}\n",
    "]\n",
    "\n",
    "LR_gs = GridSearchCV(LR_model, param_grid = LR_param, cv=pds, verbose = 5, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_base = LR_model.fit(TFIDF_Xtrain, y_train)\n",
    "\n",
    "LR_base_fn = 'LR_base.sav'\n",
    "\n",
    "pickle.dump(LR_base, open(LR_base_fn, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 80 candidates, totalling 80 fits\n"
     ]
    }
   ],
   "source": [
    "LR_gs.fit(TFIDF_Xtrainval, y_trainval)\n",
    "LR_bestparam = LR_gs.best_params_\n",
    "\n",
    "with open('LR_bestparam,txt', 'w') as f:\n",
    "    print(LR_bestparam, file=f)\n",
    "\n",
    "print(LR_bestparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LR_tuned = linear_model.LogisticRegression(**LR_bestparam)\n",
    "LR_tuned.fit(TFIDF_Xtrain, y_train)\n",
    "\n",
    "LR_tuned_fn = 'LR_tuned.sav'\n",
    "pickle.dump(LR_tuned, open(LR_tuned_fn, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8694711649100197"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load_LR = pickle.load(open('LR_base.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "NB_model = naive_bayes.MultinomialNB()\n",
    "\n",
    "NB_param = [\n",
    "    {'alpha' : [0.01, 0.05] + np.linspace(0.1, 1, 10).tolist() + [5.0, 10.0, 100.0]}\n",
    "]\n",
    "\n",
    "NB_gs = GridSearchCV(NB_model, param_grid = NB_param, cv=pds, verbose = 5, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_base = NB_model.fit(TFIDF_Xtrain, y_train)\n",
    "\n",
    "NB_base_fn = 'NB_base.sav'\n",
    "pickle.dump(NB_base, open(NB_base_fn, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 15 candidates, totalling 15 fits\n",
      "{'alpha': 0.01}\n"
     ]
    }
   ],
   "source": [
    "NB_gs.fit(TFIDF_Xtrainval, y_trainval)\n",
    "NB_bestparam = NB_gs.best_params_\n",
    "\n",
    "with open('NB_bestparam.txt', 'w') as f:\n",
    "    print(NB_bestparam, file=f)\n",
    "\n",
    "print(NB_bestparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_tuned = naive_bayes.MultinomialNB(**NB_bestparam)\n",
    "NB_tuned.fit(TFIDF_Xtrain, y_train)\n",
    "\n",
    "NB_tuned_fn = 'NB_tuned.sav'\n",
    "pickle.dump(NB_tuned, open(NB_tuned_fn, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_model = svm.SVC(probability=True)\n",
    "\n",
    "SVM_param = [\n",
    "    {'kernel' : ['linear'], 'C' : [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]}\n",
    "]\n",
    "\n",
    "SVM_gs = GridSearchCV(SVM_model, param_grid = SVM_param, cv=pds, verbose = 5, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_base = SVM_model.fit(TFIDF_Xtrain, y_train)\n",
    "\n",
    "SVM_base_fn = 'SVM_base.sav'\n",
    "pickle.dump(SVM_base, open(SVM_base_fn, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_gs.fit(TFIDF_Xtrainval, y_trainval)\n",
    "SVM_bestparam = SVM_gs.best_params_\n",
    "\n",
    "with open('SVM_bestparam.txt', 'w') as f:\n",
    "    print(SVM_bestparam, file=f)\n",
    "\n",
    "print(SVM_bestparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_tuned = svm.SVC(probability=True, **SVM_bestparam)\n",
    "SVM_tuned.fit(TFIDF_Xtrain, y_train)\n",
    "\n",
    "SVM_tuned_fn = 'SVM_tuned.sav'\n",
    "pickle.dump(SVM_tuned, open(SVM_tuned_fn, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model = ensemble.RandomForestClassifier()\n",
    "\n",
    "RF_param = {\n",
    "    'n_estimators' : [10, 50, 100, 200], \n",
    "    'max_depth' : [1, 5, 10, None]\n",
    "}\n",
    "\n",
    "RF_gs = GridSearchCV(RF_model, param_grid = RF_param, cv=pds, verbose = 5, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_base = RF_model.fit(TFIDF_Xtrain, y_train)\n",
    "\n",
    "RF_base_fn = 'RF_base.sav'\n",
    "pickle.dump(RF_base, open(RF_base_fn, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 16 candidates, totalling 16 fits\n",
      "{'max_depth': None, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "RF_gs.fit(TFIDF_Xtrainval, y_trainval)\n",
    "RF_bestparam = RF_gs.best_params_\n",
    "\n",
    "with open('RF_bestparam.txt', 'w') as f:\n",
    "    print(RF_bestparam, file=f)\n",
    "\n",
    "print(RF_bestparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_tuned = ensemble.RandomForestClassifier(**RF_bestparam)\n",
    "RF_tuned.fit(TFIDF_Xtrain, y_train)\n",
    "\n",
    "RF_tuned_fn = 'RF_tuned.sav'\n",
    "pickle.dump(RF_tuned, open(RF_tuned_fn, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_model = neighbors.KNeighborsClassifier()\n",
    "\n",
    "KNN_param = {\n",
    "    'n_neighbors' : [5, 8, 10, 15], \n",
    "    'weights' : ['uniform', 'distance'],\n",
    "    'metric' : ['minkowski', 'euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "KNN_gs = GridSearchCV(KNN_model, param_grid = KNN_param, cv=pds, verbose = 5, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_base = KNN_model.fit(TFIDF_Xtrain, y_train)\n",
    "\n",
    "KNN_base_fn = 'KNN_base.sav'\n",
    "pickle.dump(KNN_base, open(KNN_base_fn, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 24 candidates, totalling 24 fits\n"
     ]
    }
   ],
   "source": [
    "KNN_gs.fit(TFIDF_Xtrainval, y_trainval)\n",
    "KNN_bestparam = KNN_gs.best_params_\n",
    "\n",
    "with open('KNN_bestparam.txt', 'w') as f:\n",
    "    print(KNN_bestparam, file=f)\n",
    "\n",
    "print(KNN_bestparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_tuned = neighbors.KNeighborsClassifier(n_neighbors=15)\n",
    "KNN_tuned.fit(TFIDF_Xtrain, y_train)\n",
    "\n",
    "KNN_tuned_fn = 'KNN_tuned.sav'\n",
    "pickle.dump(KNN_tuned, open(KNN_tuned_fn, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEED FORWARD NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_model = neural_network.MLPClassifier()\n",
    "\n",
    "ANN_param = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)], 'activation': ['logistic', 'relu'], \n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive']\n",
    "}\n",
    "\n",
    "ANN_gs = GridSearchCV(ANN_model, param_grid = ANN_param, cv=pds, verbose = 5, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_base= ANN_model.fit(TFIDF_Xtrain, y_train)\n",
    "\n",
    "ANN_base_fn = 'ANN_base.sav'\n",
    "pickle.dump(ANN_base, open(ANN_base_fn, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_gs.fit(TFIDF_Xtrainval, y_trainval)\n",
    "ANN_bestparam = ANN_gs.best_params_\n",
    "\n",
    "with open('ANN_bestparam,txt', 'w') as f:\n",
    "    print(ANN_bestparam, file=f)\n",
    "\n",
    "print(ANN_bestparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_tuned = neural_network.MLPClassifier(**ANN_bestparam)\n",
    "ANN_tuned.fit(TFIDF_Xtrain, y_train)\n",
    "\n",
    "ANN_tuned_fn = 'ANN_tuned.sav'\n",
    "pickle.dump(ANN_tuned, open(ANN_tuned_fn, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65cc6a082bbdb51aba06bbf1d78c1b93987957587a078c9335da8e443a5b7d28"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
