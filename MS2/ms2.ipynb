{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 2\n",
    "Frederik Kallestrup Mastratis (qln174)  \n",
    "Dongyu Liu (dlf327)  \n",
    "Shamim Tariq Akram (zmx145)  \n",
    "Celina Aurora Nguyen (szf345)  \n",
    "\n",
    "Group 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 & 2\n",
    "\n",
    "We have choosen the following schema for the tables in the database:\n",
    "\n",
    "- A(id, domain, type, url, content, timestamps, title, summary)\n",
    "\n",
    "- T(id:int, tagid:string)\n",
    "\n",
    "- AU(a_id:int, author:string)\n",
    "\n",
    "- K(a_id, keyword:string)\n",
    "\n",
    "- MK(a_id, keyword:string)\n",
    "\n",
    "Where italicization denotes that the field is (part of) the primary key.\n",
    "With this design only the primary key is the superkey for the \n",
    "non-trivial functional dependencies. This also makes the schema trivially BCNF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "\n",
    "# Loading the first 10000 rows to compile faster\n",
    "df_load = pd.read_csv(\"1mio-raw.csv\", delimiter = \",\", nrows = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits a string into list\n",
    "def string_splitter(string):\n",
    "    lst = str(string).split(\", \")\n",
    "    filter_obj = filter(lambda x: x != \"\", lst)\n",
    "    return list(filter_obj)\n",
    "\n",
    "# Strip a string representation of list of strings\n",
    "def string_stripper(string):\n",
    "    lst = [i.strip() for i in string[1:-1].replace('\\'',\"\").split(',')]\n",
    "    filter_obj = filter(lambda x: x != \"\", lst)\n",
    "    return list(filter_obj)\n",
    "\n",
    "def string_filter(lst):\n",
    "    filters = [lambda x: not x.isdigit(), lambda x: x != \"\"]\n",
    "    filter_obj = filter(lambda x: all([f(x) for f in filters]), lst)\n",
    "    return list(filter_obj)\n",
    "\n",
    "df = df_load.copy()\n",
    "\n",
    "# Dropping columns (setting new ID column later)\n",
    "df = df.drop(columns = ['Unnamed: 0', 'id', 'source'])\n",
    "\n",
    "# Set new ID column\n",
    "df = df.rename_axis('id').reset_index()\n",
    "df.set_index('id')\n",
    "\n",
    "df = df.astype({'domain':str, 'type':str, 'url':str, 'content':str, 'scraped_at':str, 'inserted_at':str,\n",
    "        'updated_at':str, 'title':str, 'authors':str, 'keywords':str, 'meta_keywords':str,\n",
    "        'meta_description':str, 'tags':str, 'summary':str}, copy = False)\n",
    "\n",
    "# Convert blank fields into NaN\n",
    "#df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "# Replace 'nan' strings with NaN\n",
    "df = df.replace(\"nan\", np.nan)\n",
    "\n",
    "# Convert all strings into lower case:\n",
    "df = df.applymap(lambda s: s.lower() if type(s) == str else s)\n",
    "\n",
    "# Clean types\n",
    "type_set = ['fake', 'satire', 'bias', 'conspiracy', 'state', 'junksci', 'hate', 'clickbait', 'unreliable', 'political', 'reliable','rumor']\n",
    "df['type'] = df['type'].apply(lambda x: np.nan if x not in type_set else x)\n",
    "\n",
    "# Clean timestamps\n",
    "for column in ['scraped_at','inserted_at','updated_at']:\n",
    "    df[column] = df[column].apply(lambda x: pd.to_datetime(x, errors='coerce'))\n",
    "\n",
    "# Clean auhtors - separate into list of strings\n",
    "df['authors'] = df['authors'].apply(lambda x: string_splitter(x) if pd.notnull(x) else x)\n",
    "\n",
    "# Clean metakeywords - strip a string representation of list of strings\n",
    "df['meta_keywords'] = df['meta_keywords'].apply(string_stripper)\n",
    "\n",
    "# Clean tags\n",
    "df['tags'] = df['tags'].apply(lambda x: string_splitter(x) if pd.notnull(x) else x)\n",
    "df['tags'] = df['tags'].apply(lambda x: string_filter(x) if isinstance(x, list) else x)\n",
    "\n",
    "# Replace NaN into empty lists\n",
    "for column in ['authors', 'keywords', 'meta_keywords', 'tags']:\n",
    "    df[column] = df[column].fillna(\"\").apply(list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>domain</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>inserted_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>keywords</th>\n",
       "      <th>meta_keywords</th>\n",
       "      <th>meta_description</th>\n",
       "      <th>tags</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>express.co.uk</td>\n",
       "      <td>rumor</td>\n",
       "      <td>https://www.express.co.uk/news/science/738402/...</td>\n",
       "      <td>life is an illusion, at least on a quantum lev...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>is life an illusion? researchers prove 'realit...</td>\n",
       "      <td>[sean martin]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>the universe ceases to exist when we are not l...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>barenakedislam.com</td>\n",
       "      <td>hate</td>\n",
       "      <td>http://barenakedislam.com/category/donald-trum...</td>\n",
       "      <td>unfortunately, he hasn’t yet attacked her for ...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>donald trump</td>\n",
       "      <td>[linda rivera, conrad calvano, az gal, lincoln...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>barenakedislam.com</td>\n",
       "      <td>hate</td>\n",
       "      <td>http://barenakedislam.com/category/donald-trum...</td>\n",
       "      <td>the los angeles police department has been den...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>donald trump</td>\n",
       "      <td>[linda rivera, conrad calvano, az gal, lincoln...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>barenakedislam.com</td>\n",
       "      <td>hate</td>\n",
       "      <td>http://barenakedislam.com/2017/12/24/more-winn...</td>\n",
       "      <td>the white house has decided to quietly withdra...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>more winning! israeli intelligence source, deb...</td>\n",
       "      <td>[cleavis nowell, cleavisnowell, clarence j. fe...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>barenakedislam.com</td>\n",
       "      <td>hate</td>\n",
       "      <td>http://barenakedislam.com/2017/12/25/oh-trump-...</td>\n",
       "      <td>“the time has come to cut off the tongues of t...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>“oh, trump, you coward, you just wait, we will...</td>\n",
       "      <td>[f.n. lehner, don spilman, clarence j. feinour...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>http://beforeitsnews.com/tea-party/2017/12/a-c...</td>\n",
       "      <td>a christmas opportunity for unity\\n\\nheadline:...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>a christmas opportunity for unity</td>\n",
       "      <td>[freedom bunker]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>http://beforeitsnews.com/tea-party/2017/12/our...</td>\n",
       "      <td>our christmas gift to you\\n\\nheadline: bitcoin...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>our christmas gift to you</td>\n",
       "      <td>[freedom bunker]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>canadafreepress.com</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>http://canadafreepress.com/print_friendly/a-le...</td>\n",
       "      <td>subscribe to canada free press for free\\n\\nthe...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>a letter to the senate</td>\n",
       "      <td>[alan joel, because without america, there is ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[conservative news, conservative newspaper]</td>\n",
       "      <td>news, politics, editorials, commentary, canada...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>canadafreepress.com</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>http://canadafreepress.com/print_friendly/obam...</td>\n",
       "      <td>obama has consistently talked about how he is ...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>obama’s policy proposals are the opposite of “...</td>\n",
       "      <td>[alan joel, because without america, there is ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[conservative news, conservative newspaper]</td>\n",
       "      <td>news, politics, editorials, commentary, canada...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>canadafreepress.com</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>http://canadafreepress.com/print_friendly/the-...</td>\n",
       "      <td>the wall street journal had an excellent artic...</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>the rise of prosecutorial abuses</td>\n",
       "      <td>[alan joel, because without america, there is ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[conservative news, conservative newspaper]</td>\n",
       "      <td>news, politics, editorials, commentary, canada...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id               domain        type  \\\n",
       "0        0        express.co.uk       rumor   \n",
       "1        1   barenakedislam.com        hate   \n",
       "2        2   barenakedislam.com        hate   \n",
       "3        3   barenakedislam.com        hate   \n",
       "4        4   barenakedislam.com        hate   \n",
       "...    ...                  ...         ...   \n",
       "9995  9995    beforeitsnews.com        fake   \n",
       "9996  9996    beforeitsnews.com        fake   \n",
       "9997  9997  canadafreepress.com  conspiracy   \n",
       "9998  9998  canadafreepress.com  conspiracy   \n",
       "9999  9999  canadafreepress.com  conspiracy   \n",
       "\n",
       "                                                    url  \\\n",
       "0     https://www.express.co.uk/news/science/738402/...   \n",
       "1     http://barenakedislam.com/category/donald-trum...   \n",
       "2     http://barenakedislam.com/category/donald-trum...   \n",
       "3     http://barenakedislam.com/2017/12/24/more-winn...   \n",
       "4     http://barenakedislam.com/2017/12/25/oh-trump-...   \n",
       "...                                                 ...   \n",
       "9995  http://beforeitsnews.com/tea-party/2017/12/a-c...   \n",
       "9996  http://beforeitsnews.com/tea-party/2017/12/our...   \n",
       "9997  http://canadafreepress.com/print_friendly/a-le...   \n",
       "9998  http://canadafreepress.com/print_friendly/obam...   \n",
       "9999  http://canadafreepress.com/print_friendly/the-...   \n",
       "\n",
       "                                                content  \\\n",
       "0     life is an illusion, at least on a quantum lev...   \n",
       "1     unfortunately, he hasn’t yet attacked her for ...   \n",
       "2     the los angeles police department has been den...   \n",
       "3     the white house has decided to quietly withdra...   \n",
       "4     “the time has come to cut off the tongues of t...   \n",
       "...                                                 ...   \n",
       "9995  a christmas opportunity for unity\\n\\nheadline:...   \n",
       "9996  our christmas gift to you\\n\\nheadline: bitcoin...   \n",
       "9997  subscribe to canada free press for free\\n\\nthe...   \n",
       "9998  obama has consistently talked about how he is ...   \n",
       "9999  the wall street journal had an excellent artic...   \n",
       "\n",
       "                     scraped_at                inserted_at  \\\n",
       "0    2018-01-25 16:17:44.789555 2018-02-02 01:19:41.756632   \n",
       "1    2018-01-25 16:17:44.789555 2018-02-02 01:19:41.756632   \n",
       "2    2018-01-25 16:17:44.789555 2018-02-02 01:19:41.756632   \n",
       "3    2018-01-25 16:17:44.789555 2018-02-02 01:19:41.756632   \n",
       "4    2018-01-25 16:17:44.789555 2018-02-02 01:19:41.756632   \n",
       "...                         ...                        ...   \n",
       "9995 2018-01-25 16:17:44.789555 2018-02-02 01:19:41.756632   \n",
       "9996 2018-01-25 16:17:44.789555 2018-02-02 01:19:41.756632   \n",
       "9997 2018-01-25 16:17:44.789555 2018-02-02 01:19:41.756632   \n",
       "9998 2018-01-25 16:17:44.789555 2018-02-02 01:19:41.756632   \n",
       "9999 2018-01-25 16:17:44.789555 2018-02-02 01:19:41.756632   \n",
       "\n",
       "                     updated_at  \\\n",
       "0    2018-02-02 01:19:41.756664   \n",
       "1    2018-02-02 01:19:41.756664   \n",
       "2    2018-02-02 01:19:41.756664   \n",
       "3    2018-02-02 01:19:41.756664   \n",
       "4    2018-02-02 01:19:41.756664   \n",
       "...                         ...   \n",
       "9995 2018-02-02 01:19:41.756664   \n",
       "9996 2018-02-02 01:19:41.756664   \n",
       "9997 2018-02-02 01:19:41.756664   \n",
       "9998 2018-02-02 01:19:41.756664   \n",
       "9999 2018-02-02 01:19:41.756664   \n",
       "\n",
       "                                                  title  \\\n",
       "0     is life an illusion? researchers prove 'realit...   \n",
       "1                                          donald trump   \n",
       "2                                          donald trump   \n",
       "3     more winning! israeli intelligence source, deb...   \n",
       "4     “oh, trump, you coward, you just wait, we will...   \n",
       "...                                                 ...   \n",
       "9995                  a christmas opportunity for unity   \n",
       "9996                          our christmas gift to you   \n",
       "9997                             a letter to the senate   \n",
       "9998  obama’s policy proposals are the opposite of “...   \n",
       "9999                   the rise of prosecutorial abuses   \n",
       "\n",
       "                                                authors keywords  \\\n",
       "0                                         [sean martin]       []   \n",
       "1     [linda rivera, conrad calvano, az gal, lincoln...       []   \n",
       "2     [linda rivera, conrad calvano, az gal, lincoln...       []   \n",
       "3     [cleavis nowell, cleavisnowell, clarence j. fe...       []   \n",
       "4     [f.n. lehner, don spilman, clarence j. feinour...       []   \n",
       "...                                                 ...      ...   \n",
       "9995                                   [freedom bunker]       []   \n",
       "9996                                   [freedom bunker]       []   \n",
       "9997  [alan joel, because without america, there is ...       []   \n",
       "9998  [alan joel, because without america, there is ...       []   \n",
       "9999  [alan joel, because without america, there is ...       []   \n",
       "\n",
       "                                    meta_keywords  \\\n",
       "0                                              []   \n",
       "1                                              []   \n",
       "2                                              []   \n",
       "3                                              []   \n",
       "4                                              []   \n",
       "...                                           ...   \n",
       "9995                                           []   \n",
       "9996                                           []   \n",
       "9997  [conservative news, conservative newspaper]   \n",
       "9998  [conservative news, conservative newspaper]   \n",
       "9999  [conservative news, conservative newspaper]   \n",
       "\n",
       "                                       meta_description tags  summary  \n",
       "0     the universe ceases to exist when we are not l...   []      NaN  \n",
       "1                                                   NaN   []      NaN  \n",
       "2                                                   NaN   []      NaN  \n",
       "3                                                   NaN   []      NaN  \n",
       "4                                                   NaN   []      NaN  \n",
       "...                                                 ...  ...      ...  \n",
       "9995                                                NaN   []      NaN  \n",
       "9996                                                NaN   []      NaN  \n",
       "9997  news, politics, editorials, commentary, canada...   []      NaN  \n",
       "9998  news, politics, editorials, commentary, canada...   []      NaN  \n",
       "9999  news, politics, editorials, commentary, canada...   []      NaN  \n",
       "\n",
       "[10000 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TEST CELL\n",
    "df.to_csv('test.csv', index=False)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function connection.commit>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generates the tables of our database\n",
    "\n",
    "tables = [\"artikel\", \"author\", \"tags\", \"keywords\", \"metakeywords\"]\n",
    "\n",
    "create_tables_all = [\n",
    "    \"\"\" \n",
    "    CREATE TABLE artikel (\n",
    "        id INT, \n",
    "        domain VARCHAR, \n",
    "        type VARCHAR, \n",
    "        url VARCHAR, \n",
    "        content VARCHAR, \n",
    "        scraped_at TIMESTAMP, \n",
    "        inserted_at TIMESTAMP,\n",
    "        updated_at TIMESTAMP, \n",
    "        title VARCHAR (256), \n",
    "        meta_description VARCHAR, \n",
    "        summary VARCHAR,\n",
    "\n",
    "        PRIMARY KEY (id) \n",
    "    );\n",
    "    \"\"\"\n",
    "    ,\n",
    "    \"\"\"\n",
    "    CREATE TABLE author (\n",
    "        a_id INT,\n",
    "        author VARCHAR,\n",
    "        PRIMARY KEY (a_id, author),\n",
    "        FOREIGN KEY (a_id)\n",
    "            REFERENCES artikel (id)\n",
    "            ON UPDATE CASCADE ON DELETE CASCADE\n",
    "    );\n",
    "    \"\"\"\n",
    "    ,\n",
    "    \"\"\" \n",
    "    CREATE TABLE tags (\n",
    "        a_id INT, \n",
    "        tag VARCHAR, \n",
    "        PRIMARY KEY (a_id, tag),\n",
    "        FOREIGN KEY (a_id)\n",
    "            REFERENCES artikel (id)\n",
    "            ON UPDATE CASCADE ON DELETE CASCADE\n",
    "    );\n",
    "    \"\"\"\n",
    "    ,\n",
    "    \"\"\"\n",
    "    CREATE TABLE keywords (\n",
    "        a_id INT, \n",
    "        keyword VARCHAR,\n",
    "        PRIMARY KEY (a_id, keyword),\n",
    "        FOREIGN KEY (a_id)\n",
    "            REFERENCES artikel (id)\n",
    "            ON UPDATE CASCADE ON DELETE CASCADE\n",
    "    );\n",
    "    \"\"\"\n",
    "    ,\n",
    "    \"\"\"\n",
    "    CREATE TABLE metakeywords (\n",
    "        a_id INT, \n",
    "        mkeyword VARCHAR,\n",
    "        PRIMARY KEY (a_id, mkeyword),\n",
    "        FOREIGN KEY (a_id)\n",
    "            REFERENCES artikel (id)\n",
    "            ON UPDATE CASCADE ON DELETE CASCADE\n",
    "    );\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "# FOR TAs please configure this with your own settings\n",
    "conn = psycopg2.connect(dbname=\"fakenewsdb\", user=\"postgres\", password=\"1234\")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for table in tables:\n",
    "    cursor.execute(\"DROP TABLE IF EXISTS \" + table + \" CASCADE;\")\n",
    "\n",
    "for sql in create_tables_all:\n",
    "    cursor.execute(sql)\n",
    "\n",
    "conn.commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function connection.commit>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set of functions that puts the data from pd.dataframe into the right tables. Explodes the dataframe columns with\n",
    "# list of strings into seperate entries each with their own key (a_id, string)\n",
    "\n",
    "def projectrow2tuple(fields, row):\n",
    "    return tuple(map(lambda f: row[f], fields))\n",
    "\n",
    "def insertstring(table, n):\n",
    "    return \"INSERT INTO {} VALUES ({}) ON CONFLICT DO NOTHING\".format(table, \", \".join(map(lambda _: '%s', range(n))))\n",
    "\n",
    "def multi_insert(server, a_id, insert, xs):\n",
    "    for x in xs:\n",
    "        server.execute(insert, (a_id, x))\n",
    "    \n",
    "\n",
    "def insert_csv2rows(server, csv_row):\n",
    "    A_domain = ['id', 'domain', 'type', 'url', 'content', 'scraped_at',\n",
    "       'inserted_at', 'updated_at', 'title', 'meta_description', 'summary']\n",
    "    AU_domain = ['id', 'authors']\n",
    "    T_domain = ['id', 'tags']\n",
    "    K_domain = ['id', 'keywords']\n",
    "    MK_domain = ['id', 'meta_keywords']\n",
    "    \n",
    "    Atuple = projectrow2tuple(A_domain, csv_row)\n",
    "    (a_id, tags) = projectrow2tuple(T_domain, csv_row)\n",
    "    (_, au) = projectrow2tuple(AU_domain, csv_row)\n",
    "    (_, kws) = projectrow2tuple(K_domain, csv_row)\n",
    "    (_, mkws) = projectrow2tuple(MK_domain, csv_row)\n",
    "\n",
    "    Ainsert = insertstring(\"artikel\", len(Atuple))\n",
    "    Tinsert = insertstring(\"tags\", 2)\n",
    "    AUinsert = insertstring(\"author\", 2)\n",
    "    Kinsert = insertstring(\"keywords\", 2)\n",
    "    MKinsert = insertstring(\"metakeywords\", 2)\n",
    "\n",
    "    server.execute(Ainsert, Atuple)\n",
    "    insert = lambda ins, xs: multi_insert(server, a_id, ins, xs)\n",
    "    insert(Tinsert, tags)\n",
    "    insert(AUinsert, au)\n",
    "    insert(Kinsert, kws)\n",
    "    insert(MKinsert, mkws)\n",
    "\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    insert_csv2rows(cursor, row)\n",
    "\n",
    "conn.commit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Writing queries for Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('christianpost.com',\n",
       "  'reliable',\n",
       "  datetime.datetime(2018, 1, 25, 16, 17, 44, 789555))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QUERY 1\n",
    "\n",
    "query1 = \"\"\"\n",
    "    SELECT distinct domain, type, scraped_at \n",
    "    FROM artikel\n",
    "    WHERE type = 'reliable' AND scraped_at >= '2018-01-15'\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute('rollback')\n",
    "cursor.execute(query1)\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(525, 'freedom bunker')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QUERY 2\n",
    "\n",
    "query2 = \"\"\"\n",
    "    SELECT author\n",
    "    FROM (\n",
    "        SELECT COUNT(a_id) AS cnt, author \n",
    "        FROM author \n",
    "        WHERE a_id IN (\n",
    "            SELECT id\n",
    "            FROM artikel\n",
    "            WHERE type = 'fake'\n",
    "        ) \n",
    "        GROUP BY author\n",
    "    ) AS x\n",
    "    WHERE cnt = (SELECT MAX(cnt) FROM x)\n",
    "\"\"\"\n",
    "\n",
    "# This gives a max, but doesnt take into account if multiple authors write max number of fake articles\n",
    "query2_pseudomax = \"\"\"\n",
    "    SELECT COUNT(a_id), author \n",
    "    FROM author \n",
    "    WHERE a_id IN (\n",
    "        SELECT id\n",
    "        FROM artikel\n",
    "        WHERE type = 'fake'\n",
    "    )\n",
    "    GROUP BY author ORDER BY COUNT(a_id) DESC LIMIT 1\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute('rollback')\n",
    "cursor.execute(query2_pseudomax)\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QUERY 3 - Need to join the metakeywords table on id and concatenate a single strings with keywords sorted in alphabetical order\n",
    "# then we can use that to compare with other entries in the tables - Didnt have time to finish\n",
    "\n",
    "query3 = \"\"\"\n",
    "    SELECT a_id, COUNT(*)\n",
    "    FROM metakeywords\n",
    "    GROUP BY a_id, mkeyword\n",
    "    HAVING COUNT(*) > 1\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute('rollback')\n",
    "cursor.execute(query3)\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "Writing queries for Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3615, 'beforeitsnews.com'),\n",
       " (22, 'thecommonsenseshow.com'),\n",
       " (18, 'conservativefighters.com')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QUERY 1 - FINDING THE TOP 3 DOMAIN PUBLISHING THE MOST FAKE ARTICLES\n",
    "q1 = \"\"\"\n",
    "    SELECT COUNT(id), domain\n",
    "    FROM artikel\n",
    "    WHERE id IN (\n",
    "        SELECT id\n",
    "        FROM artikel\n",
    "        WHERE type = 'fake'\n",
    "    )\n",
    "    GROUP BY domain ORDER BY COUNT(id) DESC LIMIT 3\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute('rollback')\n",
    "cursor.execute(q1)\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(254, 'fake'), (169, 'political'), (105, 'conspiracy')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QUERY 2 - WHICH TYPE OF ARTICLES IS DONALD TRUMP MOST OFTEN MENTIONED IN\n",
    "\n",
    "q2 = \"\"\"\n",
    "    SELECT COUNT(id), type\n",
    "    FROM (\n",
    "      SELECT id, type, domain\n",
    "      FROM artikel\n",
    "      WHERE title LIKE '%trump%'\n",
    "    ) as x\n",
    "    GROUP BY type  ORDER BY COUNT(id) DESC LIMIT 3\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute('rollback')\n",
    "cursor.execute(q2)\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUERY 3 - No more time"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
